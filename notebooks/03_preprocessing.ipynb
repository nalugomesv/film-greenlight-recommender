{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e3f5cf",
   "metadata": {},
   "source": [
    "# 03 — Pré-processamento · Film Greenlight Recommender\n",
    "\n",
    "**Objetivo** — Padronizar tipos, tratar ausências e derivar variáveis **tabulares**\n",
    "numéricas e categóricas em um **pipeline reprodutível** (sem usar texto por enquanto).\n",
    "\n",
    "**Entradas** — `data/raw/imdb.csv`  \n",
    "**Saídas** — `models/preprocessor_tabular.pkl`, `models/meta/*.json`,  \n",
    "`data/processed/tabular_prep.npy` (*ou* `tabular_prep_csr.npz` se esparso)\n",
    "\n",
    "**Escopo (tabular)**  \n",
    "- Conversões: `Runtime_min`, `Gross_usd`, `Released_Year → Decade`.  \n",
    "- Derivações: `log1p(No_of_Votes)`, `log1p(Gross_usd)`.  \n",
    "- Tratamento de nulos: `Meta_score`, `Certificate`, `Gross_usd`, etc.  \n",
    "- Codificação: One-Hot (`Certificate`, `Decade`).  \n",
    "- Escalonamento: `StandardScaler` em numéricas.  \n",
    "- Gêneros: multi-hot (filtro por suporte mínimo).\n",
    "\n",
    "**Decisões principais**  \n",
    "- *Leakage*: todas as transformações ficam **dentro** do pipeline.  \n",
    "- *Reprodutibilidade*: `SEED` fixo.  \n",
    "- *Robustez*: logs para caudas longas; imputadores explícitos.\n",
    "\n",
    "Autora: *Ana Luiza Gomes Vieira* · Execução: *Set/2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95067f50",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas padrão\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Bibliotecas de terceiros\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225cb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações globais\n",
    "SEED = 42\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_RAW     = PROJECT_ROOT / \"data\" / \"raw\" / \"imdb.csv\"\n",
    "MODELS_DIR   = PROJECT_ROOT / \"models\"\n",
    "REPORTS_DIR  = PROJECT_ROOT / \"reports\"\n",
    "FEATURES_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "for p in (MODELS_DIR, REPORTS_DIR, FEATURES_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert DATA_RAW.exists(), f\"Arquivo não encontrado: {DATA_RAW}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ada985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(DATA_RAW)\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfefdc",
   "metadata": {},
   "source": [
    "## 1. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec9049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minutes(runtime: str) -> float:\n",
    "    m = re.search(r\"(\\d+)\", str(runtime))\n",
    "    return float(m.group(1)) if m else np.nan\n",
    "\n",
    "def to_usd(gross: str) -> float:\n",
    "    s = str(gross).replace(\",\", \"\").strip()\n",
    "    return float(s) if s and s.lower() != \"nan\" else np.nan\n",
    "\n",
    "def to_decade(year) -> float:\n",
    "    y = pd.to_numeric(year, errors=\"coerce\")\n",
    "    return np.floor(y/10)*10 if pd.notnull(y) else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885aa915",
   "metadata": {},
   "source": [
    "## 2. Conversões & Derivações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac110fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Runtime_min\"]     = df[\"Runtime\"].apply(to_minutes)\n",
    "df[\"Gross_usd\"]       = df[\"Gross\"].apply(to_usd)\n",
    "df[\"Released_Year\"]   = pd.to_numeric(df[\"Released_Year\"], errors=\"coerce\")\n",
    "df[\"Decade\"]          = df[\"Released_Year\"].apply(to_decade)\n",
    "df[\"No_of_Votes_log\"] = np.log1p(df[\"No_of_Votes\"])\n",
    "df[\"Gross_usd_log\"]   = np.log1p(df[\"Gross_usd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e0e65",
   "metadata": {},
   "source": [
    "## 3. Gêneros em Multi-hot (com filtro de suporte)\n",
    "Foi mantido apenas gêneros com **suporte mínimo** para evitar alta esparsidade em classes raras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d7ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dum = df[\"Genre\"].str.get_dummies(sep=\", \").astype(int)\n",
    "min_support = 20\n",
    "keep_genres = genre_dum.columns[genre_dum.sum() >= min_support].tolist()\n",
    "genre_dum = genre_dum[keep_genres] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8a143",
   "metadata": {},
   "source": [
    "## 4. Definição de Colunas (numéricas e categóricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7026d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_base = [\n",
    "    \"Runtime_min\",\n",
    "    \"Meta_score\",\n",
    "    \"No_of_Votes\", \"No_of_Votes_log\",\n",
    "    \"Gross_usd\",   \"Gross_usd_log\",\n",
    "]\n",
    "cat_cols = [\"Certificate\", \"Decade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48adadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = num_cols_base + keep_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0bea1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.concat([df[num_cols_base], genre_dum, df[cat_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336e36a",
   "metadata": {},
   "source": [
    "## 5. ColumnTransformer (imputação, escala e OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "])\n",
    "\n",
    "preprocessor_tab = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline, num_cols),\n",
    "        (\"cat\", cat_pipeline, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b66e6",
   "metadata": {},
   "source": [
    "## 6. Fit/Transform & Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "592464f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] shape X_prep: (999, 51)\n"
     ]
    }
   ],
   "source": [
    "X_prep = preprocessor_tab.fit_transform(features_df)\n",
    "print(\"[ok] shape X_prep:\", X_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ccb9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = set(num_cols + cat_cols)\n",
    "present  = set(features_df.columns)\n",
    "missing = expected - present\n",
    "if missing:\n",
    "    raise ValueError(f\"Colunas ausentes: {sorted(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b23412",
   "metadata": {},
   "source": [
    "## 7. Persistência de Artefatos (preprocessador, metadados e matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd6d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] preprocessor + metadados salvos.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(preprocessor_tab, MODELS_DIR / \"preprocessor_tabular.pkl\")\n",
    "\n",
    "import json\n",
    "(Path(MODELS_DIR) / \"meta\").mkdir(parents=True, exist_ok=True)\n",
    "with open(MODELS_DIR / \"meta\" / \"keep_genres.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(keep_genres, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(MODELS_DIR / \"meta\" / \"num_cols_base.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(num_cols_base, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(MODELS_DIR / \"meta\" / \"cat_cols.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cat_cols, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"[ok] preprocessor + metadados salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfbb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] matriz densa salva em data/processed/tabular_prep.npy\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "if sparse.issparse(X_prep):\n",
    "    sparse.save_npz(FEATURES_DIR / \"tabular_prep_csr.npz\", X_prep)\n",
    "    print(\"[ok] matriz esparsa salva em data/processed/tabular_prep_csr.npz\")\n",
    "else:\n",
    "    np.save(FEATURES_DIR / \"tabular_prep.npy\", X_prep)\n",
    "    print(\"[ok] matriz densa salva em data/processed/tabular_prep.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8a5c5",
   "metadata": {},
   "source": [
    "# Justificativa do Pré-processamento (Tabular)\n",
    "\n",
    "> Documentação das escolhas de pré-processamento do notebook **03 — Pré-processamento**, com base nos achados do EDA e do Overview. Texto em registro impessoal.\n",
    "\n",
    "## Objetivos e princípios\n",
    "\n",
    "- **Modularidade e reprodutibilidade**: centralizar conversões, imputações e codificações em um único `ColumnTransformer` (persistido em `models/preprocessor_tabular.pkl`).\n",
    "- **Prevenção de vazamento (leakage)**: transformações ajustadas apenas nos dados de treino quando usadas em modelagem via `Pipeline`.\n",
    "- **Robustez a nulos e caudas longas**: estratégias compatíveis com a distribuição observada e com a presença de faltantes.\n",
    "\n",
    "---\n",
    "\n",
    "## Conversões e derivações\n",
    "\n",
    "- **`Runtime → Runtime_min`**  \n",
    "  Extração dos minutos de strings do tipo `\"142 min\"`, viabilizando uso como variável numérica.\n",
    "\n",
    "- **`Gross → Gross_usd`**  \n",
    "  Remoção de vírgulas e conversão para `float`. A coluna apresenta ~17% de faltantes; imputação realizada no pipeline (mediana) para evitar descarte de linhas.\n",
    "\n",
    "- **`Released_Year → Decade`**  \n",
    "  Substituição do ano bruto pela **década**. A decisão reduz o risco de induzir relação espúria “quanto mais recente, melhor” e captura tendências temporais coerentes com o EDA.\n",
    "\n",
    "- **`No_of_Votes_log = log1p(No_of_Votes)` e `Gross_usd_log = log1p(Gross_usd)`**  \n",
    "  Transformações logarítmicas aplicadas devido às **caudas longas** identificadas. Reduzem assimetria, aproximam relações lineares e estabilizam variância.  \n",
    "  Mantêm-se **ambas as versões** (bruta e log) para permitir que os modelos selecionem a escala mais informativa.\n",
    "\n",
    "---\n",
    "\n",
    "## Categóricas e multi-label\n",
    "\n",
    "- **`Certificate` e `Decade`**  \n",
    "  Variáveis de **baixa cardinalidade** (conforme EDA). Codificação por **One-Hot** com `handle_unknown=\"ignore\"` para tolerância a categorias inéditas no treino.\n",
    "\n",
    "- **`Genre` (multi-label) → multi-hot**  \n",
    "  Expansão por `str.get_dummies(sep=\", \")`, uma vez que um filme pode pertencer a vários gêneros.  \n",
    "  **Filtro de suporte**: retenção apenas de gêneros com **≥ 20** ocorrências para reduzir esparsidade e ruído de classes raras (compatível com a dispersão observada).\n",
    "\n",
    "---\n",
    "\n",
    "## Tratamento de valores ausentes\n",
    "\n",
    "- **Numéricas**: `SimpleImputer(strategy=\"median\")` — mediana é estável sob outliers e compatível com distribuições assimétricas.  \n",
    "- **Categóricas**: `SimpleImputer(strategy=\"most_frequent\")` — opção simples e eficaz para variáveis discretas como `Certificate` e `Decade`.  \n",
    "- **Cascata com logs**: faltantes em `Gross_usd` implicam `NaN` em `Gross_usd_log`; ambas são imputadas no pipeline, evitando perda de observações.\n",
    "\n",
    "---\n",
    "\n",
    "## Escalonamento\n",
    "\n",
    "- **`StandardScaler`** aplicado às variáveis numéricas (incluindo dummies 0/1).  \n",
    "  A padronização favorece modelos com regularização (p. ex., ElasticNet), equalizando magnitudes sem alterar a informação binária.\n",
    "\n",
    "---\n",
    "\n",
    "## Consistência entre treino e inferência\n",
    "\n",
    "- Persistência de metadados em `models/meta/` (`keep_genres.json`, `num_cols_base.json`, `cat_cols.json`).  \n",
    "  Garante reconstrução da **mesma matriz de features** em produção (ordem de colunas e conjunto de gêneros), evitando erros de alinhamento.\n",
    "\n",
    "---\n",
    "\n",
    "## Escopo deliberadamente tabular\n",
    "\n",
    "- O texto (*Overview*) permanece fora deste pipeline. A opção visa **modularidade**: NLP (TF-IDF, modelos e tuning) encontra-se documentado no notebook específico e pode ser acoplado posteriormente via `ColumnTransformer`.\n",
    "\n",
    "---\n",
    "\n",
    "## Alinhamento com o EDA/Overview\n",
    "\n",
    "- **Caudas longas** em `Gross` e `No_of_Votes` → uso de `log1p`.  \n",
    "- **Tendências temporais** melhor capturadas por **década** do que por ano.  \n",
    "- **Gênero multi-label** com **muitas classes raras** → multi-hot com **limiar de suporte**.  \n",
    "- **Faltantes relevantes** (p. ex., `Gross`, `Meta_score`, `Certificate`) → imputação explícita e transparente.\n",
    "\n",
    "---\n",
    "\n",
    "## Riscos e mitigação\n",
    "\n",
    "- **Classes raras** nos gêneros podem introduzir ruído → mitigado por **limiar de suporte** e regularização na modelagem.  \n",
    "- **Imputação** pode enviesar se os nulos não forem aleatórios → possível extensão com **indicadores de imputação** (flags 0/1) em versões futuras.  \n",
    "- **Escalonamento de dummies** pode causar estranheza conceitual → não altera a informação; padroniza magnitudes para regularização.\n",
    "\n",
    "---\n",
    "\n",
    "## Métricas e avaliação (ligação com modelagem)\n",
    "\n",
    "- Para previsão de **`IMDB_Rating`** (problema de **regressão**), adotam-se **RMSE** (sensível a grandes erros) e **MAE** (robusto a outliers) como métricas complementares. A escolha reflete a natureza contínua da variável-alvo, com faixa relativamente estreita observada no EDA.\n",
    "\n",
    "---\n",
    "\n",
    "## Benefícios do desenho adotado\n",
    "\n",
    "- **Pipeline único** e versionável (`joblib`), com **reprodutibilidade** assegurada (SEED e metadados).  \n",
    "- **Menor viés de escala** e **menor sensibilidade a outliers** via log e padronização.  \n",
    "- **Representação adequada de gêneros** (multi-label) sem explosão desnecessária de dimensionalidade, graças ao filtro de suporte.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
